# üîß RF-DETR + CVAT Kompletn√≠ Guide
**Definitivn√≠ n√°vod pro tr√©nov√°n√≠ RF-DETR s CVAT COCO daty**

## üìã Obsah
- [üéØ Co tento guide ≈ôe≈°√≠](#-co-tento-guide-≈ôe≈°√≠)
- [üñ•Ô∏è Po≈æadavky](#Ô∏è-po≈æadavky) 
- [üöÄ Instalace](#-instalace-na-nov√©m-poƒç√≠taƒçi)
- [üìÅ Nov√Ω dataset z CVAT](#-nov√Ω-dataset-z-cvat)
- [üèÉ Spu≈°tƒõn√≠ trainingu](#-spu≈°tƒõn√≠-trainingu)
- [üîß ≈òe≈°en√≠ probl√©m≈Ø](#-≈ôe≈°en√≠-probl√©m≈Ø)

---

## üéØ Co tento guide ≈ôe≈°√≠

### ‚ùå Probl√©my RF-DETR s CVAT daty:
1. **Single-class bug**: RF-DETR pou≈æ√≠v√° `len()` m√≠sto `max(category_id)`
2. **iscrowd probl√©m**: CVAT exportuje v≈°echny objekty jako `iscrowd=1`
3. **Chybƒõj√≠c√≠ supercategory**: RF-DETR oƒçek√°v√° pole kter√© CVAT neprodukuje
4. **Background class**: RF-DETR pot≈ôebuje +1 pro background t≈ô√≠du

### ‚úÖ Na≈°e ≈ôe≈°en√≠:
- **2 Python skripty** kter√© v≈°e vy≈ôe≈°√≠ automaticky
- **Ruƒçn√° oprava** RF-DETR k√≥du (nutn√° jen jednou)
- **Univerz√°ln√≠** - funguje pro 1 i v√≠ce kategori√≠

---

## üñ•Ô∏è Po≈æadavky

### Hardware
- **GPU**: NVIDIA s 8GB+ VRAM (RTX 3070+)
- **RAM**: 16GB+
- **Disk**: 10GB voln√©ho m√≠sta

### Software  
- **Python**: 3.8-3.11
- **CUDA**: 11.8+ nebo 12.x
- **Git**

---

## üöÄ Instalace na nov√©m poƒç√≠taƒçi

### Krok 1: Virtu√°ln√≠ prost≈ôed√≠
```bash
python3 -m venv rf_detr_env
source rf_detr_env/bin/activate  # Linux/Mac
# rf_detr_env\Scripts\activate   # Windows
```

### Krok 2: Z√°vislosti
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install rfdetr supervision datasets pillow
```

### Krok 3: ‚ö†Ô∏è **KRITICK√Å RF-DETR OPRAVA**

**POZOR**: Tato oprava je POVINN√Å pro ka≈ædou instalaci!

1. **Najdi RF-DETR cestu:**
```python
import rfdetr
print(rfdetr.__file__)
# V√Ωstup: /path/to/env/lib/python3.10/site-packages/rfdetr/__init__.py
```

2. **Uprav soubor**: `/path/to/env/lib/python3.10/site-packages/rfdetr/detr.py`

3. **≈ò√°dek ~130** (v `train_from_config`):
```python
# P≈òED - CHYBN√ù:
num_classes = len(anns["categories"])

# PO - OPRAVEN√ù: 
num_classes = max([category['id'] for category in anns["categories"]])
```

4. **≈ò√°dek ~140**:
```python
# P≈òED:
self.model.reinitialize_detection_head(num_classes)

# PO:
self.model.reinitialize_detection_head(num_classes + 1)
```

5. **≈ò√°dek ~158**:
```python
# P≈òED:
all_kwargs = {**model_config, **train_config, **kwargs}

# PO: 
all_kwargs = {**model_config, **train_config, **kwargs, "num_classes": num_classes + 1}
```

### Krok 4: Test opravy
```python
# test_fix.py
import tempfile, json, os
from rfdetr import RFDETRMedium

test_coco = {
    "images": [{"id": 1, "file_name": "test.jpg", "width": 640, "height": 480}],
    "annotations": [{"id": 1, "image_id": 1, "category_id": 1, "bbox": [0,0,10,10], "area": 100, "iscrowd": 0}],
    "categories": [{"id": 1, "name": "test_class"}]
}

with tempfile.TemporaryDirectory() as tmpdir:
    train_dir = os.path.join(tmpdir, "train")
    os.makedirs(train_dir)
    
    with open(os.path.join(train_dir, "_annotations.coco.json"), "w") as f:
        json.dump(test_coco, f)
    
    try:
        with open(os.path.join(train_dir, "_annotations.coco.json"), "r") as f:
            anns = json.load(f)
            num_classes = max([category['id'] for category in anns["categories"]])
            print(f"‚úÖ OPRAVA FUNGUJE: {num_classes} kategori√≠ + 1 background = {num_classes + 1}")
    except Exception as e:
        print(f"‚ùå OPRAVA NEFUNGUJE: {e}")
```

```bash
python test_fix.py
```

---

## üìÅ Nov√Ω dataset z CVAT

### Krok 1: Export z CVAT
1. V CVAT: **Export dataset** ‚Üí **COCO 1.0** ‚Üí St√°hni ZIP
2. **Funguje pro 1 i v√≠ce kategori√≠ automaticky**

### Krok 2: St√°hni na≈°e skripty

**`quick_cvat_fix.py`** - Oprava CVAT exportu:
```python
#!/usr/bin/env python3
"""
üîß Quick CVAT Dataset Fix for RF-DETR
Oprav√≠: iscrowd 1‚Üí0, p≈ôid√° supercategory, rozdƒõl√≠ train/valid/test
"""

import json, shutil, os, argparse, random
from pathlib import Path

def fix_cvat_coco_export(cvat_export_path, output_path, split_ratios=(0.8, 0.1, 0.1)):
    print("üîß Opravuji CVAT COCO export pro RF-DETR...")
    
    cvat_path = Path(cvat_export_path)
    output_path = Path(output_path)
    
    # Najdi annotation soubor
    ann_file = None
    for path in [cvat_path / "annotations" / "instances_default.json", 
                 cvat_path / "instances_default.json"]:
        if path.exists():
            ann_file = path
            break
    
    if not ann_file:
        raise FileNotFoundError(f"COCO soubor nenalezen v {cvat_path}")
    
    with open(ann_file, 'r') as f:
        data = json.load(f)
    
    print(f"üìä Dataset: {len(data['images'])} obr√°zk≈Ø, {len(data['annotations'])} anotac√≠, {len(data['categories'])} kategori√≠")
    for cat in data['categories']:
        print(f"    * ID {cat['id']}: {cat['name']}")
    
    # OPRAVA 1: iscrowd 1 ‚Üí 0
    crowd_count = 0
    for ann in data['annotations']:
        if ann.get('iscrowd', 0) == 1:
            ann['iscrowd'] = 0
            crowd_count += 1
    if crowd_count > 0:
        print(f"‚úÖ {crowd_count} objekt≈Ø opraveno z 'crowd' na norm√°ln√≠")
    
    # OPRAVA 2: supercategory
    supercategory_count = 0
    for cat in data['categories']:
        if 'supercategory' not in cat:
            cat['supercategory'] = 'object'
            supercategory_count += 1
    if supercategory_count > 0:
        print(f"‚úÖ {supercategory_count} kategori√≠ doplnƒõno supercategory")
    
    # Najdi obr√°zky
    image_dir = None
    for img_dir in [cvat_path / "images" / "default", cvat_path / "images", cvat_path]:
        if img_dir.exists() and list(img_dir.glob("*.jpg")):
            image_dir = img_dir
            break
    
    if not image_dir:
        raise FileNotFoundError(f"Obr√°zky nenalezeny v {cvat_path}")
    
    # Rozdƒõlen√≠ train/valid/test
    random.seed(42)
    images = data['images'].copy()
    random.shuffle(images)
    
    n_total = len(images)
    n_train = int(split_ratios[0] * n_total)
    n_valid = int(split_ratios[1] * n_total)
    
    # Zajisti alespo≈à nƒõco pro valid
    if n_total > 2 and n_valid == 0:
        n_valid = 1
        n_train = n_total - n_valid - max(1, int(split_ratios[2] * n_total))
    
    train_images = images[:n_train]
    valid_images = images[n_train:n_train + n_valid]
    test_images = images[n_train + n_valid:]
    
    print(f"üìà Rozdƒõlen√≠: Train {len(train_images)}, Valid {len(valid_images)}, Test {len(test_images)}")
    
    # Vytvo≈ô RF-DETR strukturu
    output_path.mkdir(parents=True, exist_ok=True)
    
    for split, split_images in [('train', train_images), ('valid', valid_images), ('test', test_images)]:
        split_dir = output_path / split
        split_dir.mkdir(parents=True, exist_ok=True)
        
        if not split_images:
            # Pr√°zdn√Ω split pro RF-DETR
            empty_data = {'images': [], 'annotations': [], 'categories': data['categories']}
            with open(split_dir / "_annotations.coco.json", 'w') as f:
                json.dump(empty_data, f)
            print(f"‚ö†Ô∏è  {split}: pr√°zdn√Ω (RF-DETR vy≈æaduje)")
            continue
        
        # Kop√≠ruj obr√°zky
        image_ids = {img['id'] for img in split_images}
        for img in split_images:
            src = image_dir / img['file_name']
            dst = split_dir / img['file_name']
            if src.exists():
                shutil.copy2(src, dst)
        
        # Anotace pro split
        split_annotations = [ann for ann in data['annotations'] if ann['image_id'] in image_ids]
        split_data = {
            'images': split_images,
            'annotations': split_annotations, 
            'categories': data['categories']
        }
        
        with open(split_dir / "_annotations.coco.json", 'w') as f:
            json.dump(split_data, f)
        
        print(f"‚úÖ {split}: {len(split_images)} obr√°zk≈Ø, {len(split_annotations)} anotac√≠")
    
    print(f"üéâ Dataset p≈ôipraven: {output_path}")
    return output_path

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Oprav√≠ CVAT export pro RF-DETR")
    parser.add_argument('input_dir', help='CVAT export slo≈æka')
    parser.add_argument('output_dir', help='V√Ωstupn√≠ slo≈æka')
    args = parser.parse_args()
    
    fix_cvat_coco_export(args.input_dir, args.output_dir)
```

**`train_universal.py`** - Univerz√°ln√≠ training:
```python
#!/usr/bin/env python3
"""
üöÄ Universal RF-DETR Training for CVAT Data
Univerz√°ln√≠ training script s auto-konfigurac√≠
"""

import argparse, torch, json, os
from pathlib import Path
from rfdetr import RFDETRMedium

def get_optimal_batch_size():
    """Auto batch size podle GPU"""
    if not torch.cuda.is_available():
        return 2
    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
    if vram_gb >= 24: return 8
    elif vram_gb >= 16: return 6  
    elif vram_gb >= 12: return 4
    elif vram_gb >= 8: return 3
    else: return 2

def validate_dataset(dataset_dir):
    """Validuje dataset a RF-DETR opravy"""
    dataset_path = Path(dataset_dir)
    if not dataset_path.exists():
        raise FileNotFoundError(f"Dataset neexistuje: {dataset_dir}")
    
    for split in ['train', 'valid', 'test']:
        ann_file = dataset_path / split / "_annotations.coco.json"
        if ann_file.exists():
            with open(ann_file, 'r') as f:
                data = json.load(f)
            n_imgs, n_anns, n_cats = len(data['images']), len(data['annotations']), len(data['categories'])
            print(f"‚úÖ {split}: {n_imgs} obr√°zk≈Ø, {n_anns} anotac√≠, {n_cats} kategori√≠")
            
            crowd_count = sum(1 for ann in data['annotations'] if ann.get('iscrowd', 0) == 1)
            if crowd_count > 0:
                print(f"‚ö†Ô∏è  {split}: {crowd_count} crowd objekt≈Ø!")

def check_rfdetr_fixes():
    """Kontrola RF-DETR oprav"""
    try:
        import rfdetr
        detr_file = Path(rfdetr.__file__).parent / "detr.py"
        with open(detr_file, 'r') as f:
            content = f.read()
        
        if "max([category['id'] for category in anns[\"categories\"]])" in content:
            print("‚úÖ RF-DETR Fix 1: Single-class bug opraven")
        else:
            print("‚ùå RF-DETR Fix 1: CHYB√ç! Viz guide")
            return False
        
        if "num_classes + 1" in content:
            print("‚úÖ RF-DETR Fix 2: Background class opraven")
        else:
            print("‚ùå RF-DETR Fix 2: CHYB√ç!")
            return False
        
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è  Nelze zkontrolovat: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description="Universal RF-DETR training")
    parser.add_argument('--dataset', '-d', required=True, help='Dataset slo≈æka')
    parser.add_argument('--output', '-o', default='trained_model', help='Output slo≈æka')
    parser.add_argument('--epochs', '-e', type=int, default=50, help='Epochy')
    parser.add_argument('--batch-size', '-b', type=int, default=None, help='Batch size')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
    parser.add_argument('--device', choices=['auto', 'cuda', 'cpu'], default='auto')
    parser.add_argument('--quick-test', action='store_true', help='Jen 1 epocha')
    args = parser.parse_args()
    
    print("üöÄ RF-DETR Universal Training")
    print("=" * 50)
    
    print("\nüîç Validuji dataset...")
    validate_dataset(args.dataset)
    
    print("\nüîß Kontroluji RF-DETR opravy...")
    if not check_rfdetr_fixes():
        print("‚ùå RF-DETR nen√≠ opraven! Viz guide")
        return 1
    
    # Hardware
    device = 'cuda' if torch.cuda.is_available() else 'cpu' if args.device == 'auto' else args.device
    batch_size = get_optimal_batch_size() if args.batch_size is None else args.batch_size
    epochs = 1 if args.quick_test else args.epochs
    
    print(f"\nüñ•Ô∏è  Hardware:")
    print(f"  Device: {device}")
    if device == 'cuda':
        print(f"  GPU: {torch.cuda.get_device_name(0)}")
        print(f"  VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB")
    print(f"  Batch size: {batch_size}")
    
    if args.quick_test:
        print(f"‚ö° Quick test: {epochs} epocha")
    
    # Model
    print(f"\nü§ñ RF-DETR Medium...")
    model = RFDETRMedium()
    
    # Config
    config = {
        'dataset_dir': args.dataset,
        'epochs': epochs,
        'batch_size': batch_size,
        'lr': args.lr,
        'lr_encoder': args.lr * 0.1,
        'weight_decay': 1e-4,
        'device': device,
        'output_dir': args.output,
        'early_stopping': True,
        'early_stopping_patience': 10,
        'warmup_epochs': min(5, epochs//4),
        'lr_drop': max(epochs//2, 10),
        'use_ema': True
    }
    
    print(f"\nüìã Training config:")
    for k, v in config.items():
        print(f"  {k}: {v}")
    
    os.makedirs(args.output, exist_ok=True)
    with open(Path(args.output) / "config.json", 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"\nüéØ Spou≈°t√≠m training...")
    try:
        model.train(**config)
        print("\nüéâ Training dokonƒçen!")
        best_model = Path(args.output) / "checkpoint_best_total.pth"
        if best_model.exists():
            print(f"üèÜ Nejlep≈°√≠ model: {best_model}")
        return 0
    except Exception as e:
        print(f"\n‚ùå Chyba: {e}")
        return 1

if __name__ == "__main__":
    exit(main())
```

### Krok 3: Rozbal a oprav CVAT export
```bash
unzip dataset.zip
python quick_cvat_fix.py dataset dataset_prepared
```

**P≈ô√≠klad v√Ωstupu:**
```
üìä Dataset: 123 obr√°zk≈Ø, 241 anotac√≠, 1 kategori√≠
    * ID 1: Screwdriver
‚úÖ 241 objekt≈Ø opraveno z 'crowd' na norm√°ln√≠
‚úÖ 1 kategori√≠ doplnƒõno supercategory
üìà Rozdƒõlen√≠: Train 98, Valid 12, Test 13
üéâ Dataset p≈ôipraven: dataset_prepared
```

---

## üèÉ Spu≈°tƒõn√≠ trainingu

### Z√°kladn√≠ training
```bash
python train_universal.py --dataset dataset_prepared
```

### Pokroƒçil√© nastaven√≠
```bash
python train_universal.py --dataset dataset_prepared --epochs 100 --lr 5e-5 --output my_model
```

### Quick test (1 epocha)
```bash
python train_universal.py --dataset dataset_prepared --quick-test
```

**V√Ωstup trainingu:**
```
üöÄ RF-DETR Universal Training
==================================================
üîç Validuji dataset...
‚úÖ train: 98 obr√°zk≈Ø, 193 anotac√≠, 1 kategori√≠
‚úÖ valid: 12 obr√°zk≈Ø, 24 anotac√≠, 1 kategori√≠  
‚úÖ test: 13 obr√°zk≈Ø, 24 anotac√≠, 1 kategori√≠

üîß Kontroluji RF-DETR opravy...
‚úÖ RF-DETR Fix 1: Single-class bug opraven
‚úÖ RF-DETR Fix 2: Background class opraven

üñ•Ô∏è  Hardware:
  Device: cuda
  GPU: NVIDIA GeForce RTX 4090
  VRAM: 24.0GB
  Batch size: 8

üéØ Spou≈°t√≠m training...
num_classes mismatch: model has 90 classes, but your dataset has 1 classes
reinitializing your detection head with 2 classes (including background).

Epoch [1/50]: loss: 0.2480, bbox: 0.2480, giou: 0.2779, mAP@50: 0.435
üéâ Training dokonƒçen!
üèÜ Nejlep≈°√≠ model: trained_model/checkpoint_best_total.pth
```

---

## üîß ≈òe≈°en√≠ probl√©m≈Ø

### ‚ùå "Zero losses" nebo "mAP = -1"
**P≈ô√≠ƒçina**: iscrowd oprava neprobƒõhla
**≈òe≈°en√≠**: Zkontroluj v `_annotations.coco.json` ≈æe `"iscrowd": 0`

### ‚ùå "num_classes mismatch"  
**P≈ô√≠ƒçina**: RF-DETR oprava neprobƒõhla
**≈òe≈°en√≠**: Zkontroluj opravu v `detr.py`

### ‚ùå "supercategory KeyError"
**P≈ô√≠ƒçina**: Star√Ω quick_cvat_fix.py
**≈òe≈°en√≠**: Pou≈æij aktu√°ln√≠ verzi scriptu

### ‚ùå "CUDA out of memory"
**≈òe≈°en√≠**: Sni≈æ batch size: `--batch-size 2`

### ‚ùå "UnidentifiedImageError"
**P≈ô√≠ƒçina**: Po≈°kozen√© nebo chybƒõj√≠c√≠ obr√°zky
**≈òe≈°en√≠**: Zkontroluj ≈æe v≈°echny obr√°zky existuj√≠ a jsou validn√≠

---

## üéØ Multi-Category p≈ô√≠klad

### CVAT s v√≠ce kategoriemi:
```json
{
  "categories": [
    {"id": 1, "name": "screwdriver"},
    {"id": 2, "name": "hammer"}, 
    {"id": 3, "name": "wrench"}
  ]
}
```

### Automatick√° detekce:
```
üìä Dataset: 456 obr√°zk≈Ø, 892 anotac√≠, 3 kategori√≠
    * ID 1: screwdriver
    * ID 2: hammer
    * ID 3: wrench
‚úÖ 892 objekt≈Ø opraveno z 'crowd' na norm√°ln√≠

num_classes=4 (3 + background)
class_names=['screwdriver', 'hammer', 'wrench']
```

### Inference s v√≠ce kategoriemi:
```python
from rfdetr import RFDETRMedium
model = RFDETRMedium.from_checkpoint("my_model/checkpoint_best_total.pth")
results = model.predict("tools.jpg", confidence=0.5)
# [
#   {"label": "screwdriver", "confidence": 0.95, "bbox": [10,10,50,50]},
#   {"label": "hammer", "confidence": 0.87, "bbox": [60,60,40,40]}
# ]
```

---

## ‚úÖ Checklist pro nov√Ω projekt

### P≈ô√≠prava:
- [ ] RF-DETR nainstalov√°n + opravy aplikov√°ny
- [ ] CVAT dataset exportov√°n jako COCO 1.0
- [ ] `quick_cvat_fix.py` sta≈æen a spu≈°tƒõn
- [ ] Dataset struktura: `train/`, `valid/`, `test/` s `_annotations.coco.json`

### Training:
- [ ] `train_universal.py` sta≈æen
- [ ] GPU dostupn√© (ovƒõ≈ô `nvidia-smi`)
- [ ] Training spu≈°tƒõn: `python train_universal.py --dataset dataset_prepared`
- [ ] Progress monitored: `tail -f trained_model/train.log`

### Po trainingu:
- [ ] Model checkpoint existuje: `trained_model/checkpoint_best_total.pth`
- [ ] Inference test: `model.predict("test.jpg")`
- [ ] V√Ωsledky uspokojiv√©

---

## üéâ Z√ÅVƒöR

**‚úÖ UNIVERZ√ÅLN√ç ≈òE≈†EN√ç pro RF-DETR + CVAT:**

- **2 skripty** vy≈ôe≈°√≠ v≈°e automaticky
- **1 oprava** RF-DETR k√≥du (jednou nav≈ædy)
- **Funguje** pro 1 i v√≠ce kategori√≠
- **Jednoduch√Ω** workflow pro ka≈æd√Ω nov√Ω dataset

**P≈Øvodn√≠ probl√©m vy≈ôe≈°en**: *"mam yto data exportovnae z cvat do coco 1.0 a chtel bych upravit kod aby dokazal moje data trenovat"* ‚úÖ

**Workflow je nyn√≠:**
1. CVAT ‚Üí Export COCO 1.0
2. `python quick_cvat_fix.py dataset dataset_prepared`  
3. `python train_universal.py --dataset dataset_prepared`
4. üéâ Profit!

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------

Tak≈æe pro tvou novou slo≈æku napr "screw-test" s CVAT exportem bude≈° pot≈ôebovat spustit:

`python¬†quick_cvat_fix.py¬†screw-test¬†dataset_prepared_new`

Kde:
screw-test = tv√° vstupn√≠ slo≈æka s CVAT COCO 1.0 exportem (obsahuje annotations/instances_default.json a images/default/)
dataset_prepared_new = v√Ωstupn√≠ slo≈æka kde se vytvo≈ô√≠ RF-DETR kompatibiln√≠ struktura

**Script automaticky:**

1. Najde instances_default.json v annotations
2. Oprav√≠ v≈°echny iscrowd: 1 na iscrowd: 0 (kritick√° oprava!)
3. Rozdƒõl√≠ obr√°zky na train/valid/test (80/10/10)
4. Vytvo≈ô√≠ RF-DETR strukturu s _annotations.coco.json v ka≈æd√© slo≈æce
5. Zkop√≠ruje obr√°zky do spr√°vn√Ωch slo≈æek
6. Po spu≈°tƒõn√≠ bude≈° m√≠t p≈ôipraveno pro training:

`python train_universal.py --dataset dataset_prepared_new --output screwdriver_model_v2`


# Norm√°ln√≠ training s grafy (default)
python train_universal.py --dataset dataset_prepared --output my_model

# Training bez graf≈Ø (rychlej≈°√≠)
python train_universal.py --dataset dataset_prepared --output my_model --no-plots

# Vytvo≈ô grafy pro existuj√≠c√≠ model
python -c "from train_universal import create_training_plots; create_training_plots('screwdriver_model')"

Najdi nejlep≈°√≠ checkpoint
    best_checkpoint = output_path / "checkpoint_best_total.pth"

source pytcvatsrew/bin/activate && python quick_cvat_fix.py screw-test dataset_prepared_new
source pytcvatsrew/bin/activate && python train_universal.py --dataset dataset_prepared_new --output fresh_screwdriver_model --epochs 20