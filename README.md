# ğŸ”§ RF-DETR + CVAT KompletnÃ­ Guide
**DefinitivnÃ­ nÃ¡vod pro trÃ©novÃ¡nÃ­ RF-DETR s CVAT COCO daty**

## ğŸ“‹ Obsah
- [ğŸ¯ Co tento guide Å™eÅ¡Ã­](#-co-tento-guide-Å™eÅ¡Ã­)
- [ğŸ–¥ï¸ PoÅ¾adavky](#ï¸-poÅ¾adavky) 
- [ğŸš€ Instalace](#-instalace-na-novÃ©m-poÄÃ­taÄi)
- [ğŸ“ NovÃ½ dataset z CVAT](#-novÃ½-dataset-z-cvat)
- [ğŸƒ SpuÅ¡tÄ›nÃ­ trainingu](#-spuÅ¡tÄ›nÃ­-trainingu)
- [ğŸ”§ Å˜eÅ¡enÃ­ problÃ©mÅ¯](#-Å™eÅ¡enÃ­-problÃ©mÅ¯)

---

## ğŸ¯ Co tento guide Å™eÅ¡Ã­

### âŒ ProblÃ©my RF-DETR s CVAT daty:
1. **Single-class bug**: RF-DETR pouÅ¾Ã­vÃ¡ `len()` mÃ­sto `max(category_id)`
2. **iscrowd problÃ©m**: CVAT exportuje vÅ¡echny objekty jako `iscrowd=1`
3. **ChybÄ›jÃ­cÃ­ supercategory**: RF-DETR oÄekÃ¡vÃ¡ pole kterÃ© CVAT neprodukuje
4. **Background class**: RF-DETR potÅ™ebuje +1 pro background tÅ™Ã­du

### âœ… NaÅ¡e Å™eÅ¡enÃ­:
- **2 Python skripty** kterÃ© vÅ¡e vyÅ™eÅ¡Ã­ automaticky
- **RuÄnÃ¡ oprava** RF-DETR kÃ³du (nutnÃ¡ jen jednou)
- **UniverzÃ¡lnÃ­** - funguje pro 1 i vÃ­ce kategoriÃ­

---

## ğŸ–¥ï¸ PoÅ¾adavky

### Hardware
- **GPU**: NVIDIA s 8GB+ VRAM (RTX 3070+)
- **RAM**: 16GB+
- **Disk**: 10GB volnÃ©ho mÃ­sta

### Software  
- **Python**: 3.8-3.11
- **CUDA**: 11.8+ nebo 12.x
- **Git**

---

## ğŸš€ Instalace na novÃ©m poÄÃ­taÄi

### Krok 1: VirtuÃ¡lnÃ­ prostÅ™edÃ­
```bash
python3 -m venv rf_detr_env
source rf_detr_env/bin/activate  # Linux/Mac
# rf_detr_env\Scripts\activate   # Windows
```

### Krok 2: ZÃ¡vislosti
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install rfdetr supervision datasets pillow
```

### Krok 3: âš ï¸ **KRITICKÃ RF-DETR OPRAVA**

**POZOR**: Tato oprava je POVINNÃ pro kaÅ¾dou instalaci!

1. **Najdi RF-DETR cestu:**
```python
import rfdetr
print(rfdetr.__file__)
# VÃ½stup: /path/to/env/lib/python3.10/site-packages/rfdetr/__init__.py
```

2. **Uprav soubor**: `/path/to/env/lib/python3.10/site-packages/rfdetr/detr.py`

3. **Å˜Ã¡dek ~130** (v `train_from_config`):
```python
# PÅ˜ED - CHYBNÃ:
num_classes = len(anns["categories"])

# PO - OPRAVENÃ: 
num_classes = max([category['id'] for category in anns["categories"]])
```

4. **Å˜Ã¡dek ~140**:
```python
# PÅ˜ED:
self.model.reinitialize_detection_head(num_classes)

# PO:
self.model.reinitialize_detection_head(num_classes + 1)
```

5. **Å˜Ã¡dek ~158**:
```python
# PÅ˜ED:
all_kwargs = {**model_config, **train_config, **kwargs}

# PO: 
all_kwargs = {**model_config, **train_config, **kwargs, "num_classes": num_classes + 1}
```

### Krok 4: Test opravy
```python
# test_fix.py
import tempfile, json, os
from rfdetr import RFDETRMedium

test_coco = {
    "images": [{"id": 1, "file_name": "test.jpg", "width": 640, "height": 480}],
    "annotations": [{"id": 1, "image_id": 1, "category_id": 1, "bbox": [0,0,10,10], "area": 100, "iscrowd": 0}],
    "categories": [{"id": 1, "name": "test_class"}]
}

with tempfile.TemporaryDirectory() as tmpdir:
    train_dir = os.path.join(tmpdir, "train")
    os.makedirs(train_dir)
    
    with open(os.path.join(train_dir, "_annotations.coco.json"), "w") as f:
        json.dump(test_coco, f)
    
    try:
        with open(os.path.join(train_dir, "_annotations.coco.json"), "r") as f:
            anns = json.load(f)
            num_classes = max([category['id'] for category in anns["categories"]])
            print(f"âœ… OPRAVA FUNGUJE: {num_classes} kategoriÃ­ + 1 background = {num_classes + 1}")
    except Exception as e:
        print(f"âŒ OPRAVA NEFUNGUJE: {e}")
```

```bash
python test_fix.py
```

---

## ğŸ“ NovÃ½ dataset z CVAT

### Krok 1: Export z CVAT
1. V CVAT: **Export dataset** â†’ **COCO 1.0** â†’ StÃ¡hni ZIP
2. **Funguje pro 1 i vÃ­ce kategoriÃ­ automaticky**

### Krok 2: StÃ¡hni naÅ¡e skripty

**`quick_cvat_fix.py`** - Oprava CVAT exportu:
```python
#!/usr/bin/env python3
"""
ğŸ”§ Quick CVAT Dataset Fix for RF-DETR
OpravÃ­: iscrowd 1â†’0, pÅ™idÃ¡ supercategory, rozdÄ›lÃ­ train/valid/test
"""

import json, shutil, os, argparse, random
from pathlib import Path

def fix_cvat_coco_export(cvat_export_path, output_path, split_ratios=(0.8, 0.1, 0.1)):
    print("ğŸ”§ Opravuji CVAT COCO export pro RF-DETR...")
    
    cvat_path = Path(cvat_export_path)
    output_path = Path(output_path)
    
    # Najdi annotation soubor
    ann_file = None
    for path in [cvat_path / "annotations" / "instances_default.json", 
                 cvat_path / "instances_default.json"]:
        if path.exists():
            ann_file = path
            break
    
    if not ann_file:
        raise FileNotFoundError(f"COCO soubor nenalezen v {cvat_path}")
    
    with open(ann_file, 'r') as f:
        data = json.load(f)
    
    print(f"ğŸ“Š Dataset: {len(data['images'])} obrÃ¡zkÅ¯, {len(data['annotations'])} anotacÃ­, {len(data['categories'])} kategoriÃ­")
    for cat in data['categories']:
        print(f"    * ID {cat['id']}: {cat['name']}")
    
    # OPRAVA 1: iscrowd 1 â†’ 0
    crowd_count = 0
    for ann in data['annotations']:
        if ann.get('iscrowd', 0) == 1:
            ann['iscrowd'] = 0
            crowd_count += 1
    if crowd_count > 0:
        print(f"âœ… {crowd_count} objektÅ¯ opraveno z 'crowd' na normÃ¡lnÃ­")
    
    # OPRAVA 2: supercategory
    supercategory_count = 0
    for cat in data['categories']:
        if 'supercategory' not in cat:
            cat['supercategory'] = 'object'
            supercategory_count += 1
    if supercategory_count > 0:
        print(f"âœ… {supercategory_count} kategoriÃ­ doplnÄ›no supercategory")
    
    # Najdi obrÃ¡zky
    image_dir = None
    for img_dir in [cvat_path / "images" / "default", cvat_path / "images", cvat_path]:
        if img_dir.exists() and list(img_dir.glob("*.jpg")):
            image_dir = img_dir
            break
    
    if not image_dir:
        raise FileNotFoundError(f"ObrÃ¡zky nenalezeny v {cvat_path}")
    
    # RozdÄ›lenÃ­ train/valid/test
    random.seed(42)
    images = data['images'].copy()
    random.shuffle(images)
    
    n_total = len(images)
    n_train = int(split_ratios[0] * n_total)
    n_valid = int(split_ratios[1] * n_total)
    
    # Zajisti alespoÅˆ nÄ›co pro valid
    if n_total > 2 and n_valid == 0:
        n_valid = 1
        n_train = n_total - n_valid - max(1, int(split_ratios[2] * n_total))
    
    train_images = images[:n_train]
    valid_images = images[n_train:n_train + n_valid]
    test_images = images[n_train + n_valid:]
    
    print(f"ğŸ“ˆ RozdÄ›lenÃ­: Train {len(train_images)}, Valid {len(valid_images)}, Test {len(test_images)}")
    
    # VytvoÅ™ RF-DETR strukturu
    output_path.mkdir(parents=True, exist_ok=True)
    
    for split, split_images in [('train', train_images), ('valid', valid_images), ('test', test_images)]:
        split_dir = output_path / split
        split_dir.mkdir(parents=True, exist_ok=True)
        
        if not split_images:
            # PrÃ¡zdnÃ½ split pro RF-DETR
            empty_data = {'images': [], 'annotations': [], 'categories': data['categories']}
            with open(split_dir / "_annotations.coco.json", 'w') as f:
                json.dump(empty_data, f)
            print(f"âš ï¸  {split}: prÃ¡zdnÃ½ (RF-DETR vyÅ¾aduje)")
            continue
        
        # KopÃ­ruj obrÃ¡zky
        image_ids = {img['id'] for img in split_images}
        for img in split_images:
            src = image_dir / img['file_name']
            dst = split_dir / img['file_name']
            if src.exists():
                shutil.copy2(src, dst)
        
        # Anotace pro split
        split_annotations = [ann for ann in data['annotations'] if ann['image_id'] in image_ids]
        split_data = {
            'images': split_images,
            'annotations': split_annotations, 
            'categories': data['categories']
        }
        
        with open(split_dir / "_annotations.coco.json", 'w') as f:
            json.dump(split_data, f)
        
        print(f"âœ… {split}: {len(split_images)} obrÃ¡zkÅ¯, {len(split_annotations)} anotacÃ­")
    
    print(f"ğŸ‰ Dataset pÅ™ipraven: {output_path}")
    return output_path

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="OpravÃ­ CVAT export pro RF-DETR")
    parser.add_argument('input_dir', help='CVAT export sloÅ¾ka')
    parser.add_argument('output_dir', help='VÃ½stupnÃ­ sloÅ¾ka')
    args = parser.parse_args()
    
    fix_cvat_coco_export(args.input_dir, args.output_dir)
```

**`train_universal.py`** - UniverzÃ¡lnÃ­ training:
```python
#!/usr/bin/env python3
"""
ğŸš€ Universal RF-DETR Training for CVAT Data
UniverzÃ¡lnÃ­ training script s auto-konfiguracÃ­
"""

import argparse, torch, json, os
from pathlib import Path
from rfdetr import RFDETRMedium

def get_optimal_batch_size():
    """Auto batch size podle GPU"""
    if not torch.cuda.is_available():
        return 2
    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
    if vram_gb >= 24: return 8
    elif vram_gb >= 16: return 6  
    elif vram_gb >= 12: return 4
    elif vram_gb >= 8: return 3
    else: return 2

def validate_dataset(dataset_dir):
    """Validuje dataset a RF-DETR opravy"""
    dataset_path = Path(dataset_dir)
    if not dataset_path.exists():
        raise FileNotFoundError(f"Dataset neexistuje: {dataset_dir}")
    
    for split in ['train', 'valid', 'test']:
        ann_file = dataset_path / split / "_annotations.coco.json"
        if ann_file.exists():
            with open(ann_file, 'r') as f:
                data = json.load(f)
            n_imgs, n_anns, n_cats = len(data['images']), len(data['annotations']), len(data['categories'])
            print(f"âœ… {split}: {n_imgs} obrÃ¡zkÅ¯, {n_anns} anotacÃ­, {n_cats} kategoriÃ­")
            
            crowd_count = sum(1 for ann in data['annotations'] if ann.get('iscrowd', 0) == 1)
            if crowd_count > 0:
                print(f"âš ï¸  {split}: {crowd_count} crowd objektÅ¯!")

def check_rfdetr_fixes():
    """Kontrola RF-DETR oprav"""
    try:
        import rfdetr
        detr_file = Path(rfdetr.__file__).parent / "detr.py"
        with open(detr_file, 'r') as f:
            content = f.read()
        
        if "max([category['id'] for category in anns[\"categories\"]])" in content:
            print("âœ… RF-DETR Fix 1: Single-class bug opraven")
        else:
            print("âŒ RF-DETR Fix 1: CHYBÃ! Viz guide")
            return False
        
        if "num_classes + 1" in content:
            print("âœ… RF-DETR Fix 2: Background class opraven")
        else:
            print("âŒ RF-DETR Fix 2: CHYBÃ!")
            return False
        
        return True
    except Exception as e:
        print(f"âš ï¸  Nelze zkontrolovat: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description="Universal RF-DETR training")
    parser.add_argument('--dataset', '-d', required=True, help='Dataset sloÅ¾ka')
    parser.add_argument('--output', '-o', default='trained_model', help='Output sloÅ¾ka')
    parser.add_argument('--epochs', '-e', type=int, default=50, help='Epochy')
    parser.add_argument('--batch-size', '-b', type=int, default=None, help='Batch size')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
    parser.add_argument('--device', choices=['auto', 'cuda', 'cpu'], default='auto')
    parser.add_argument('--quick-test', action='store_true', help='Jen 1 epocha')
    args = parser.parse_args()
    
    print("ğŸš€ RF-DETR Universal Training")
    print("=" * 50)
    
    print("\nğŸ” Validuji dataset...")
    validate_dataset(args.dataset)
    
    print("\nğŸ”§ Kontroluji RF-DETR opravy...")
    if not check_rfdetr_fixes():
        print("âŒ RF-DETR nenÃ­ opraven! Viz guide")
        return 1
    
    # Hardware
    device = 'cuda' if torch.cuda.is_available() else 'cpu' if args.device == 'auto' else args.device
    batch_size = get_optimal_batch_size() if args.batch_size is None else args.batch_size
    epochs = 1 if args.quick_test else args.epochs
    
    print(f"\nğŸ–¥ï¸  Hardware:")
    print(f"  Device: {device}")
    if device == 'cuda':
        print(f"  GPU: {torch.cuda.get_device_name(0)}")
        print(f"  VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB")
    print(f"  Batch size: {batch_size}")
    
    if args.quick_test:
        print(f"âš¡ Quick test: {epochs} epocha")
    
    # Model
    print(f"\nğŸ¤– RF-DETR Medium...")
    model = RFDETRMedium()
    
    # Config
    config = {
        'dataset_dir': args.dataset,
        'epochs': epochs,
        'batch_size': batch_size,
        'lr': args.lr,
        'lr_encoder': args.lr * 0.1,
        'weight_decay': 1e-4,
        'device': device,
        'output_dir': args.output,
        'early_stopping': True,
        'early_stopping_patience': 10,
        'warmup_epochs': min(5, epochs//4),
        'lr_drop': max(epochs//2, 10),
        'use_ema': True
    }
    
    print(f"\nğŸ“‹ Training config:")
    for k, v in config.items():
        print(f"  {k}: {v}")
    
    os.makedirs(args.output, exist_ok=True)
    with open(Path(args.output) / "config.json", 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"\nğŸ¯ SpouÅ¡tÃ­m training...")
    try:
        model.train(**config)
        print("\nğŸ‰ Training dokonÄen!")
        best_model = Path(args.output) / "checkpoint_best_total.pth"
        if best_model.exists():
            print(f"ğŸ† NejlepÅ¡Ã­ model: {best_model}")
        return 0
    except Exception as e:
        print(f"\nâŒ Chyba: {e}")
        return 1

if __name__ == "__main__":
    exit(main())
```

### Krok 3: Rozbal a oprav CVAT export
```bash
unzip dataset.zip
python quick_cvat_fix.py dataset dataset_prepared
```

**PÅ™Ã­klad vÃ½stupu:**
```
ğŸ“Š Dataset: 123 obrÃ¡zkÅ¯, 241 anotacÃ­, 1 kategoriÃ­
    * ID 1: Screwdriver
âœ… 241 objektÅ¯ opraveno z 'crowd' na normÃ¡lnÃ­
âœ… 1 kategoriÃ­ doplnÄ›no supercategory
ğŸ“ˆ RozdÄ›lenÃ­: Train 98, Valid 12, Test 13
ğŸ‰ Dataset pÅ™ipraven: dataset_prepared
```

---

## ğŸƒ SpuÅ¡tÄ›nÃ­ trainingu

### ZÃ¡kladnÃ­ training
```bash
python train_universal.py --dataset dataset_prepared
```

### PokroÄilÃ© nastavenÃ­
```bash
python train_universal.py --dataset dataset_prepared --epochs 100 --lr 5e-5 --output my_model
```

### Quick test (1 epocha)
```bash
python train_universal.py --dataset dataset_prepared --quick-test
```

**VÃ½stup trainingu:**
```
ğŸš€ RF-DETR Universal Training
==================================================
ğŸ” Validuji dataset...
âœ… train: 98 obrÃ¡zkÅ¯, 193 anotacÃ­, 1 kategoriÃ­
âœ… valid: 12 obrÃ¡zkÅ¯, 24 anotacÃ­, 1 kategoriÃ­  
âœ… test: 13 obrÃ¡zkÅ¯, 24 anotacÃ­, 1 kategoriÃ­

ğŸ”§ Kontroluji RF-DETR opravy...
âœ… RF-DETR Fix 1: Single-class bug opraven
âœ… RF-DETR Fix 2: Background class opraven

ğŸ–¥ï¸  Hardware:
  Device: cuda
  GPU: NVIDIA GeForce RTX 4090
  VRAM: 24.0GB
  Batch size: 8

ğŸ¯ SpouÅ¡tÃ­m training...
num_classes mismatch: model has 90 classes, but your dataset has 1 classes
reinitializing your detection head with 2 classes (including background).

Epoch [1/50]: loss: 0.2480, bbox: 0.2480, giou: 0.2779, mAP@50: 0.435
ğŸ‰ Training dokonÄen!
ğŸ† NejlepÅ¡Ã­ model: trained_model/checkpoint_best_total.pth
```

---

## ğŸ”§ Å˜eÅ¡enÃ­ problÃ©mÅ¯

### âŒ "Zero losses" nebo "mAP = -1"
**PÅ™Ã­Äina**: iscrowd oprava neprobÄ›hla
**Å˜eÅ¡enÃ­**: Zkontroluj v `_annotations.coco.json` Å¾e `"iscrowd": 0`

### âŒ "num_classes mismatch"  
**PÅ™Ã­Äina**: RF-DETR oprava neprobÄ›hla
**Å˜eÅ¡enÃ­**: Zkontroluj opravu v `detr.py`

### âŒ "supercategory KeyError"
**PÅ™Ã­Äina**: StarÃ½ quick_cvat_fix.py
**Å˜eÅ¡enÃ­**: PouÅ¾ij aktuÃ¡lnÃ­ verzi scriptu

### âŒ "CUDA out of memory"
**Å˜eÅ¡enÃ­**: SniÅ¾ batch size: `--batch-size 2`

### âŒ "UnidentifiedImageError"
**PÅ™Ã­Äina**: PoÅ¡kozenÃ© nebo chybÄ›jÃ­cÃ­ obrÃ¡zky
**Å˜eÅ¡enÃ­**: Zkontroluj Å¾e vÅ¡echny obrÃ¡zky existujÃ­ a jsou validnÃ­

---

## ğŸ¯ Multi-Category pÅ™Ã­klad

### CVAT s vÃ­ce kategoriemi:
```json
{
  "categories": [
    {"id": 1, "name": "screwdriver"},
    {"id": 2, "name": "hammer"}, 
    {"id": 3, "name": "wrench"}
  ]
}
```

### AutomatickÃ¡ detekce:
```
ğŸ“Š Dataset: 456 obrÃ¡zkÅ¯, 892 anotacÃ­, 3 kategoriÃ­
    * ID 1: screwdriver
    * ID 2: hammer
    * ID 3: wrench
âœ… 892 objektÅ¯ opraveno z 'crowd' na normÃ¡lnÃ­

num_classes=4 (3 + background)
class_names=['screwdriver', 'hammer', 'wrench']
```

### Inference s vÃ­ce kategoriemi:
```python
from rfdetr import RFDETRMedium
model = RFDETRMedium.from_checkpoint("my_model/checkpoint_best_total.pth")
results = model.predict("tools.jpg", confidence=0.5)
# [
#   {"label": "screwdriver", "confidence": 0.95, "bbox": [10,10,50,50]},
#   {"label": "hammer", "confidence": 0.87, "bbox": [60,60,40,40]}
# ]
```

---

## âœ… Checklist pro novÃ½ projekt

### PÅ™Ã­prava:
- [ ] RF-DETR nainstalovÃ¡n + opravy aplikovÃ¡ny
- [ ] CVAT dataset exportovÃ¡n jako COCO 1.0
- [ ] `quick_cvat_fix.py` staÅ¾en a spuÅ¡tÄ›n
- [ ] Dataset struktura: `train/`, `valid/`, `test/` s `_annotations.coco.json`

### Training:
- [ ] `train_universal.py` staÅ¾en
- [ ] GPU dostupnÃ© (ovÄ›Å™ `nvidia-smi`)
- [ ] Training spuÅ¡tÄ›n: `python train_universal.py --dataset dataset_prepared`
- [ ] Progress monitored: `tail -f trained_model/train.log`

### Po trainingu:
- [ ] Model checkpoint existuje: `trained_model/checkpoint_best_total.pth`
- [ ] Inference test: `model.predict("test.jpg")`
- [ ] VÃ½sledky uspokojivÃ©

---

## ğŸ‰ ZÃVÄšR

**âœ… UNIVERZÃLNÃ Å˜EÅ ENÃ pro RF-DETR + CVAT:**

- **2 skripty** vyÅ™eÅ¡Ã­ vÅ¡e automaticky
- **1 oprava** RF-DETR kÃ³du (jednou navÅ¾dy)
- **Funguje** pro 1 i vÃ­ce kategoriÃ­
- **JednoduchÃ½** workflow pro kaÅ¾dÃ½ novÃ½ dataset

**PÅ¯vodnÃ­ problÃ©m vyÅ™eÅ¡en**: *"mam yto data exportovnae z cvat do coco 1.0 a chtel bych upravit kod aby dokazal moje data trenovat"* âœ…

**Workflow je nynÃ­:**
1. CVAT â†’ Export COCO 1.0
2. `python quick_cvat_fix.py dataset dataset_prepared`  
3. `python train_universal.py --dataset dataset_prepared`
4. ğŸ‰ Profit!

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------

TakÅ¾e pro tvou novou sloÅ¾ku napr "screw-test" s CVAT exportem budeÅ¡ potÅ™ebovat spustit:

`pythonÂ quick_cvat_fix.pyÂ screw-testÂ dataset_prepared_new`

Kde:
screw-test = tvÃ¡ vstupnÃ­ sloÅ¾ka s CVAT COCO 1.0 exportem (obsahuje annotations/instances_default.json a images/default/)
dataset_prepared_new = vÃ½stupnÃ­ sloÅ¾ka kde se vytvoÅ™Ã­ RF-DETR kompatibilnÃ­ struktura

**Script automaticky:**

1. Najde instances_default.json v annotations
2. OpravÃ­ vÅ¡echny iscrowd: 1 na iscrowd: 0 (kritickÃ¡ oprava!)
3. RozdÄ›lÃ­ obrÃ¡zky na train/valid/test (80/10/10)
4. VytvoÅ™Ã­ RF-DETR strukturu s _annotations.coco.json v kaÅ¾dÃ© sloÅ¾ce
5. ZkopÃ­ruje obrÃ¡zky do sprÃ¡vnÃ½ch sloÅ¾ek
6. Po spuÅ¡tÄ›nÃ­ budeÅ¡ mÃ­t pÅ™ipraveno pro training:

`python train_universal.py --dataset dataset_prepared_new --output screwdriver_model_v2`


# NormÃ¡lnÃ­ training s grafy (default)
python train_universal.py --dataset dataset_prepared --output my_model

# Training bez grafÅ¯ (rychlejÅ¡Ã­)
python train_universal.py --dataset dataset_prepared --output my_model --no-plots

# VytvoÅ™ grafy pro existujÃ­cÃ­ model
python -c "from train_universal import create_training_plots; create_training_plots('screwdriver_model')"

Najdi nejlepÅ¡Ã­ checkpoint
    best_checkpoint = output_path / "checkpoint_best_total.pth"

source pytcvatsrew/bin/activate && python quick_cvat_fix.py screw-test dataset_prepared_new
source pytcvatsrew/bin/activate && python train_universal.py --dataset dataset_prepared_new --output fresh_screwdriver_model --epochs 20